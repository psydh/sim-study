import streamlit as st
import google.generativeai as genai

# --- 1. ì—¬ê¸°ì— í‚¤ë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš” ---
GOOGLE_API_KEY = "AIzaSyBVLA4WTbPf-o_gPpwCUeAwuPq5b94XS5I" 

genai.configure(api_key=GOOGLE_API_KEY)
model = genai.GenerativeModel('models/gemini-1.5-flash')

st.set_page_config(page_title="ì •ì‹ ê°„í˜¸ MSE ì‹¤ìŠµ (AI)", layout="centered")

if 'step' not in st.session_state:
    st.session_state.step = 1
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

# --- 2. ì´ˆê¸° ì„¤ì • ---
if st.session_state.step == 1:
    st.title("ğŸ¥ AI ê¸°ë°˜ ì •ì‹ ê°„í˜¸ MSE ì‹¤ìŠµ")
    st.session_state.user_name = st.text_input("í•™ìƒ ì„±í•¨")
    st.session_state.topic = st.selectbox("ì‹¤ìŠµ ì£¼ì œ ì„ íƒ", [
        "ì¡°í˜„ë³‘ í™˜ì ì‚¬ì • (ì‚¬ë¡€: 35ì„¸ ì—¬ì„±, í™˜ì²­ê³¼ ë¶ˆì•ˆ)",
        "ì¡°ìš¸ì¦ í™˜ì ì‚¬ì • (ì‚¬ë¡€: 32ì„¸ ë‚¨ì„±, ì¡°ì¦ ìƒíƒœ)",
        "ìì‚´ ìœ„í—˜ í™˜ì ì‚¬ì • (ì‚¬ë¡€: 26ì„¸ ì—¬ì„±, ìì‚´ ì¶©ë™)"
    ])
    
    if st.button("ì‹¤ìŠµ ì‹œì‘"):
        st.session_state.system_prompt = f"""
        ë„ˆëŠ” ì •ì‹ ê³¼ í™˜ì ì—­í• ì„ í•˜ëŠ” ì‹œë®¬ë ˆì´í„°ì•¼. ì•„ë˜ ì„¤ì •ì— ë§ì¶°ì„œ ê°„í˜¸í•™ìƒê³¼ ëŒ€í™”í•´ì¤˜.
        ì£¼ì œ: {st.session_state.topic}
        ì§€ì¹¨: 
        1. ëŒ€í™”í•  ë•Œë§ˆë‹¤ ë„ˆì˜ í‘œì •, íƒœë„, ëª¸ì§“ ë“± ë¹„ì–¸ì–´ì  ë¬˜ì‚¬ë¥¼ [ ] ì•ˆì— ë°˜ë“œì‹œ í¬í•¨í•´.
        2. ê°„í˜¸í•™ìƒì´ MSE ì‚¬ì •ì„ í•  ìˆ˜ ìˆë„ë¡ ì¦ìƒì„ ì ì ˆíˆ ë³´ì—¬ì¤˜.
        3. ë„ˆë¬´ í˜‘ì¡°ì ì´ì§€ ì•Šê²Œ, ì‹¤ì œ í™˜ìì˜ íŠ¹ì„±ì„ ì‚´ë ¤ ëŒ€ë‹µí•´.
        4. í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•´.
        """
        st.session_state.step = 2
        st.rerun()

# --- 3. ì‹¤ì‹œê°„ AI ëŒ€í™”ì°½ ---
elif st.session_state.step == 2:
    st.header(f"ğŸ’¬ ëŒ€ìƒì ëŒ€í™” ({st.session_state.topic})")
    
    for chat in st.session_state.chat_history:
        with st.chat_message(chat["role"]):
            st.markdown(chat["content"])

    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # AI ë‹µë³€ ìƒì„±
        full_prompt = f"{st.session_state.system_prompt}\n\ní•™ìƒ ì§ˆë¬¸: {prompt}"
        response = model.generate_content(full_prompt)
        
        with st.chat_message("assistant"):
            st.markdown(response.text)
        st.session_state.chat_history.append({"role": "assistant", "content": response.text})

    if st.button("ëŒ€í™” ì¢…ë£Œ ë° ë³´ê³ ì„œ ì‘ì„±"):
        st.session_state.step = 3
        st.rerun()

# --- 4. ë³´ê³ ì„œ ë‹¨ê³„ ---
elif st.session_state.step == 3:
    st.header("ğŸ“ MSE ì‚¬ì • ë³´ê³ ì„œ")
    mse_result = st.text_area("ì‚¬ì • ê²°ê³¼ ê¸°ë¡", height=200)
    if st.button("ì œì¶œ ì™„ë£Œ"):
        st.success("ì‹¤ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‚´ìš©ì„ ìº¡ì²˜í•˜ì—¬ ì œì¶œí•˜ì„¸ìš”.")
        st.write(f"í•™ìƒ: {st.session_state.user_name}")
        st.write(f"ì‘ì„± ë‚´ìš©: {mse_result}")
        st.balloons()

